{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VESPER_COLAB.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "g4unbuRQu3eY"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4unbuRQu3eY"
      },
      "source": [
        "## When connecting to a new runtime, execute the below cell first to install the required dependencies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKnJxg69htlq"
      },
      "source": [
        "# Install all the dependencies\n",
        "!pip install mrcfile numba pyfftw scipy tqdm SimpleITK"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bz5oarS1vZyk"
      },
      "source": [
        "## Initialization Part:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8J7suM9hW79"
      },
      "source": [
        "# import pacakages\n",
        "import concurrent.futures\n",
        "import copy\n",
        "import math\n",
        "import multiprocessing\n",
        "import os\n",
        "import time\n",
        "\n",
        "import mrcfile\n",
        "import SimpleITK as sitk\n",
        "import numba\n",
        "import numpy as np\n",
        "import pyfftw\n",
        "import scipy.fft\n",
        "from numba.typed import List\n",
        "from scipy.ndimage import convolve, correlate\n",
        "from scipy.spatial.transform import Rotation as R\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQ99gpT9h-B3"
      },
      "source": [
        "# set fftw params\n",
        "pyfftw.config.PLANNER_EFFORT = \"FFTW_MEASURE\"\n",
        "pyfftw.config.NUM_THREADS = multiprocessing.cpu_count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pl_tUdKJiAKB"
      },
      "source": [
        "class mrc_obj:\n",
        "    def __init__(self, path):\n",
        "        mrc = mrcfile.open(path)\n",
        "        data = mrc.data\n",
        "        header = mrc.header\n",
        "        self.xdim = int(header.nx)\n",
        "        self.ydim = int(header.ny)\n",
        "        self.zdim = int(header.nz)\n",
        "        self.xwidth = mrc.voxel_size.x\n",
        "        self.ywidth = mrc.voxel_size.y\n",
        "        self.zwidth = mrc.voxel_size.z\n",
        "        self.cent = np.array([self.xdim * 0.5, self.ydim * 0.5, self.zdim * 0.5,\n",
        "                              ])\n",
        "        self.orig = np.array([header.origin.x, header.origin.y, header.origin.z])\n",
        "        self.data = np.swapaxes(copy.deepcopy(data), 0, 2)\n",
        "        self.dens = data.flatten()\n",
        "        self.vec = np.zeros((self.xdim, self.ydim, self.zdim, 3), dtype=\"float32\")\n",
        "        self.dsum = None\n",
        "        self.Nact = None\n",
        "        self.ave = None\n",
        "        self.std_norm_ave = None\n",
        "        self.std = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOa5S6UkiCe3"
      },
      "source": [
        "def mrc_set_vox_size(mrc, th=0.01, voxel_size=7.0):\n",
        "    # set shape and size\n",
        "    size = mrc.xdim * mrc.ydim * mrc.zdim\n",
        "    shape = (mrc.xdim, mrc.ydim, mrc.zdim)\n",
        "\n",
        "    # if th < 0 add th to all value\n",
        "    if th < 0:\n",
        "        mrc.dens = mrc.dens - th\n",
        "        th = 0.0\n",
        "\n",
        "    # zero all the values less than threshold\n",
        "    mrc.dens[mrc.dens < th] = 0.0\n",
        "    mrc.data[mrc.data < th] = 0.0\n",
        "\n",
        "    # calculate maximum distance for non-zero entries\n",
        "    non_zero_index_list = np.array(np.nonzero(mrc.data)).T\n",
        "    cent_arr = np.array(mrc.cent)\n",
        "    d2_list = np.linalg.norm(non_zero_index_list - cent_arr, axis=1)\n",
        "    dmax = max(d2_list)\n",
        "\n",
        "    print(\"#dmax=\" + str(dmax / mrc.xwidth))\n",
        "    dmax = dmax * mrc.xwidth\n",
        "\n",
        "    # set new center\n",
        "    new_cent = mrc.cent * mrc.xwidth + mrc.orig\n",
        "\n",
        "    tmp_size = 2 * dmax / voxel_size\n",
        "\n",
        "    # get the best size suitable for fft operation\n",
        "    new_xdim = pyfftw.next_fast_len(int(tmp_size))\n",
        "\n",
        "    # set new origins\n",
        "    new_orig = new_cent - 0.5 * new_xdim * voxel_size\n",
        "\n",
        "    # create new mrc object\n",
        "    mrc_new = copy.deepcopy(mrc)\n",
        "    mrc_new.orig = new_orig\n",
        "    mrc_new.xdim = new_xdim\n",
        "    mrc_new.ydim = new_xdim\n",
        "    mrc_new.zdim = new_xdim\n",
        "    mrc_new.cent = new_cent\n",
        "    mrc_new.xwidth = mrc_new.ywidth = mrc_new.zwidth = voxel_size\n",
        "\n",
        "    print(\"Nvox= \" + str(mrc_new.xdim) + \", \" + str(mrc_new.ydim) + \", \" + str(mrc_new.zdim))\n",
        "    print(\"cent= \" + str(new_cent[0]) + \", \" + str(new_cent[1]) + \", \" + str(new_cent[2]))\n",
        "    print(\"ori= \" + str(new_orig[0]) + \", \" + str(new_orig[1]) + \", \" + str(new_orig[2]))\n",
        "\n",
        "    return mrc, mrc_new"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXUZ7OpViEoP"
      },
      "source": [
        "@numba.jit(nopython=True)\n",
        "def calc(stp, endp, pos, mrc1_data, fsiv):\n",
        "    dtotal = 0.0\n",
        "    pos2 = np.zeros((3,))\n",
        "\n",
        "    for xp in range(stp[0], endp[0]):\n",
        "        rx = float(xp) - pos[0]\n",
        "        rx = rx ** 2\n",
        "        for yp in range(stp[1], endp[1]):\n",
        "            ry = float(yp) - pos[1]\n",
        "            ry = ry ** 2\n",
        "            for zp in range(stp[2], endp[2]):\n",
        "                rz = float(zp) - pos[2]\n",
        "                rz = rz ** 2\n",
        "                d2 = rx + ry + rz\n",
        "                v = mrc1_data[xp][yp][zp] * math.exp(-1.5 * d2 * fsiv)\n",
        "                dtotal += v\n",
        "                pos2[0] += v * xp\n",
        "                pos2[1] += v * yp\n",
        "                pos2[2] += v * zp\n",
        "\n",
        "    return dtotal, pos2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GH6rnozniGTD"
      },
      "source": [
        "def fastVEC(mrc_source, mrc_dest, dreso=16.0):\n",
        "\n",
        "    print(\"#Start VEC\")\n",
        "    gstep = mrc_source.xwidth\n",
        "    fs = (dreso / gstep) * 0.5\n",
        "    fs = fs ** 2\n",
        "    fsiv = 1.0 / fs\n",
        "    fmaxd = (dreso / gstep) * 2.0\n",
        "    print(\"#maxd= {fmaxd}\".format(fmaxd=fmaxd))\n",
        "    print(\"#fsiv= \" + str(fsiv))\n",
        "\n",
        "    dsum = 0.0\n",
        "    Nact = 0\n",
        "\n",
        "    for x in tqdm(range(mrc_dest.xdim)):\n",
        "        for y in range(mrc_dest.ydim):\n",
        "            for z in range(mrc_dest.zdim):\n",
        "                stp = np.zeros((3,), dtype=np.int32)\n",
        "                endp = np.zeros((3,), dtype=np.int32)\n",
        "                ind2 = 0\n",
        "                ind = 0\n",
        "\n",
        "                pos = np.zeros((3,), dtype=np.float32)\n",
        "                pos2 = np.zeros((3,), dtype=np.float32)\n",
        "\n",
        "                tmpcd = np.zeros((3,), dtype=np.float32)\n",
        "\n",
        "                v, dtotal, rd = 0.0, 0.0, 0.0\n",
        "\n",
        "                xyz_arr = np.array((x, y, z))\n",
        "                pos = (xyz_arr * mrc_dest.xwidth + mrc_dest.orig - mrc_source.orig) / mrc_source.xwidth\n",
        "\n",
        "                ind = mrc_dest.xdim * mrc_dest.ydim * z + mrc_dest.xdim * y + x\n",
        "\n",
        "                # check density\n",
        "\n",
        "                if (\n",
        "                        pos[0] < 0\n",
        "                        or pos[1] < 0\n",
        "                        or pos[2] < 0\n",
        "                        or pos[0] >= mrc_source.xdim\n",
        "                        or pos[1] >= mrc_source.ydim\n",
        "                        or pos[2] >= mrc_source.zdim\n",
        "                ):\n",
        "                    mrc_dest.dens[ind] = 0.0\n",
        "                    mrc_dest.vec[x][y][z] = 0.0\n",
        "                    continue\n",
        "\n",
        "                if mrc_source.data[int(pos[0])][int(pos[1])][int(pos[2])] == 0:\n",
        "                    mrc_dest.dens[ind] = 0.0\n",
        "                    mrc_dest.vec[x][y][z] = 0.0\n",
        "                    continue\n",
        "\n",
        "                # Start Point\n",
        "                stp = (pos - fmaxd).astype(np.int32)\n",
        "\n",
        "                # set start and end point\n",
        "                if stp[0] < 0:\n",
        "                    stp[0] = 0\n",
        "                if stp[1] < 0:\n",
        "                    stp[1] = 0\n",
        "                if stp[2] < 0:\n",
        "                    stp[2] = 0\n",
        "\n",
        "                # End Point\n",
        "                endp = (pos + fmaxd + 1).astype(np.int32)\n",
        "\n",
        "                if endp[0] >= mrc_source.xdim:\n",
        "                    endp[0] = mrc_source.xdim\n",
        "                if endp[1] >= mrc_source.ydim:\n",
        "                    endp[1] = mrc_source.ydim\n",
        "                if endp[2] >= mrc_source.zdim:\n",
        "                    endp[2] = mrc_source.zdim\n",
        "\n",
        "                # compute the total density\n",
        "                dtotal, pos2 = calc(stp, endp, pos, mrc_source.data, fsiv)\n",
        "\n",
        "                mrc_dest.dens[ind] = dtotal\n",
        "                mrc_dest.data[x][y][z] = dtotal\n",
        "\n",
        "                if dtotal == 0:\n",
        "                    mrc_dest.vec[x][y][z] = 0.0\n",
        "                    continue\n",
        "\n",
        "                rd = 1.0 / dtotal\n",
        "\n",
        "                pos2 *= rd\n",
        "\n",
        "                tmpcd = pos2 - pos\n",
        "\n",
        "                dvec = math.sqrt(tmpcd[0] ** 2 + tmpcd[1] ** 2 + tmpcd[2] ** 2)\n",
        "\n",
        "                if dvec == 0:\n",
        "                    dvec = 1.0\n",
        "\n",
        "                rdvec = 1.0 / dvec\n",
        "\n",
        "                mrc_dest.vec[x][y][z] = tmpcd * rdvec\n",
        "\n",
        "                dsum += dtotal\n",
        "                Nact += 1\n",
        "\n",
        "    print(\"#End LDP\")\n",
        "    print(dsum)\n",
        "    print(Nact)\n",
        "\n",
        "    mrc_dest.dsum = dsum\n",
        "    mrc_dest.Nact = Nact\n",
        "    mrc_dest.ave = dsum / float(Nact)\n",
        "    mrc_dest.std = np.linalg.norm(mrc_dest.dens[mrc_dest.dens > 0])\n",
        "    mrc_dest.std_norm_ave = np.linalg.norm(mrc_dest.dens[mrc_dest.dens > 0] - mrc_dest.ave)\n",
        "\n",
        "    print(\"#MAP AVE={ave} STD={std} STD_norm={std_norm}\".format(ave=mrc_dest.ave, std=mrc_dest.std,\n",
        "                                                                std_norm=mrc_dest.std_norm_ave))\n",
        "    # return False\n",
        "    return mrc_dest"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LV02gb-AiOX1"
      },
      "source": [
        "@numba.jit(nopython=True)\n",
        "def rot_pos_mtx(mtx, vec):\n",
        "    mtx = mtx.astype(np.float32)\n",
        "    vec = vec.astype(np.float32)\n",
        "    return vec @ mtx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXqoRhfviP4T"
      },
      "source": [
        "def rot_mrc(orig_mrc_data, orig_mrc_vec, angle):\n",
        "\n",
        "    # dimension set to be vec array length\n",
        "    dim = orig_mrc_vec.shape[0]\n",
        "\n",
        "    # create array for new positions\n",
        "    new_pos = np.array(np.meshgrid(np.arange(dim), np.arange(dim), np.arange(dim),)).T.reshape(-1, 3)\n",
        "\n",
        "    # set the center\n",
        "    cent = 0.5 * float(dim)\n",
        "\n",
        "    # get relative positions from center\n",
        "    new_pos = new_pos - cent\n",
        "    # print(new_pos)\n",
        "\n",
        "    # init the rotation by euler angle\n",
        "    r = R.from_euler(\"ZYX\", angle, degrees=True)\n",
        "    mtx = r.as_matrix()\n",
        "    mtx[np.isclose(mtx, 0, atol=1e-15)] = 0\n",
        "\n",
        "    # rotate the position list to get old positions\n",
        "    old_pos = rot_pos_mtx(np.flip(mtx).T, new_pos) + cent\n",
        "    \n",
        "    # horizontally combine two position array\n",
        "    combined_arr = np.hstack((old_pos, new_pos))\n",
        "\n",
        "    # filter values outside the boundaries\n",
        "    in_bound_mask = (\n",
        "        (old_pos[:, 0] >= 0)\n",
        "        & (old_pos[:, 1] >= 0)\n",
        "        & (old_pos[:, 2] >= 0)\n",
        "        & (old_pos[:, 0] < dim)\n",
        "        & (old_pos[:, 1] < dim)\n",
        "        & (old_pos[:, 2] < dim)\n",
        "    )\n",
        "\n",
        "    # get the mask of all the values inside boundary\n",
        "    combined_arr = combined_arr[in_bound_mask]\n",
        "\n",
        "    # convert the index to integer\n",
        "    combined_arr = combined_arr.astype(np.int32)\n",
        "\n",
        "    # get the old index array\n",
        "    index_arr = combined_arr[:, 0:3]\n",
        "\n",
        "    # get the index that has non-zero density by masking\n",
        "    dens_mask = orig_mrc_data[index_arr[:, 0], index_arr[:, 1], index_arr[:, 2]] != 0.0\n",
        "    non_zero_rot_list = combined_arr[dens_mask]\n",
        "\n",
        "    # get the non-zero vec and dens values\n",
        "    non_zero_vec = orig_mrc_vec[non_zero_rot_list[:, 0], non_zero_rot_list[:, 1], non_zero_rot_list[:, 2]]\n",
        "    non_zero_dens = orig_mrc_data[non_zero_rot_list[:, 0], non_zero_rot_list[:, 1], non_zero_rot_list[:, 2]]\n",
        "    new_vec = rot_pos_mtx(np.flip(mtx), non_zero_vec)\n",
        "\n",
        "    # init new vec and dens array\n",
        "    new_vec_array = np.zeros_like(orig_mrc_vec)\n",
        "    new_data_array = np.zeros_like(orig_mrc_data)\n",
        "\n",
        "    # find the new indices\n",
        "    new_ind_arr = (non_zero_rot_list[:, 3:6] + cent).astype(int)\n",
        "\n",
        "    # fill in the values to new vec and dens array\n",
        "    new_vec_array[new_ind_arr[:,0], new_ind_arr[:,1], new_ind_arr[:,2]] = new_vec\n",
        "    new_data_array[new_ind_arr[:,0], new_ind_arr[:,1], new_ind_arr[:,2]] = non_zero_dens\n",
        "\n",
        "    return new_vec_array, new_data_array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehYu88eYjZ8p"
      },
      "source": [
        "def ang_to_mtx_ZYX(angle):\n",
        "    r = R.from_euler(\"ZYX\", angle, degrees=True)\n",
        "    mtx = r.as_matrix()\n",
        "    mtx[np.isclose(mtx, 0, atol=1e-15)] = 0\n",
        "    mtx = np.flip(mtx).T\n",
        "    return mtx.astype(np.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "az2J3M-GjjIp"
      },
      "source": [
        "# find the best translation based on list of fft results\n",
        "def find_best_trans_list(input_list):\n",
        "    \n",
        "    sum_arr = np.zeros_like(input_list[0])\n",
        "    for arr in input_list:\n",
        "        sum_arr = sum_arr + arr\n",
        "    best = np.amax(sum_arr)\n",
        "    trans = np.unravel_index(sum_arr.argmax(), sum_arr.shape)\n",
        "    \n",
        "    return best, trans"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lk8Gkeq1jrNY"
      },
      "source": [
        "def get_score(\n",
        "    target_map_data, search_map_data, target_map_vec, search_map_vec, trans, ave1, ave2, std1, std2, pstd1, pstd2\n",
        "):\n",
        "\n",
        "    px, py, pz = 0, 0, 0\n",
        "    dim = target_map_data.shape[0]\n",
        "    total = 0\n",
        "\n",
        "    t = np.array(trans)\n",
        "    if trans[0] > 0.5 * dim:\n",
        "        t[0] -= dim\n",
        "    if trans[1] > 0.5 * dim:\n",
        "        t[1] -= dim\n",
        "    if trans[2] > 0.5 * dim:\n",
        "        t[2] -= dim\n",
        "\n",
        "    target_pos = np.array(np.meshgrid(np.arange(dim), np.arange(dim), np.arange(dim),)).T.reshape(-1, 3)\n",
        "\n",
        "    search_pos = target_pos + t\n",
        "\n",
        "    total += np.count_nonzero(target_map_data[target_pos[:, 0], target_pos[:, 1], target_pos[:, 2]])\n",
        "\n",
        "    combined_arr = np.hstack((target_pos, search_pos))\n",
        "\n",
        "    combined_arr = combined_arr[\n",
        "        (combined_arr[:, 3] >= 0)\n",
        "        & (combined_arr[:, 4] >= 0)\n",
        "        & (combined_arr[:, 5] >= 0)\n",
        "        & (combined_arr[:, 3] < dim)\n",
        "        & (combined_arr[:, 4] < dim)\n",
        "        & (combined_arr[:, 5] < dim)\n",
        "    ]\n",
        "\n",
        "    target_pos = combined_arr[:, 0:3]\n",
        "    search_pos = combined_arr[:, 3:6]\n",
        "\n",
        "    d1 = target_map_data[target_pos[:, 0], target_pos[:, 1], target_pos[:, 2]]\n",
        "    d2 = search_map_data[search_pos[:, 0], search_pos[:, 1], search_pos[:, 2]]\n",
        "    \n",
        "    d1 = np.where(d1 <= 0, 0.0, d1)\n",
        "    d2 = np.where(d2 <= 0, 0.0, d1)\n",
        "\n",
        "    print(np.sum(d1))\n",
        "    print(np.sum(d2))\n",
        "\n",
        "    pd1 = np.where(d1 <= 0, 0.0, d1 - ave1)\n",
        "    pd2 = np.where(d2 <= 0, 0.0, d2 - ave2)\n",
        "\n",
        "    cc = np.sum(np.multiply(d1, d2))\n",
        "    pcc = np.sum(np.multiply(pd1, pd2))\n",
        "\n",
        "    target_zero_mask = target_map_data[target_pos[:, 0], target_pos[:, 1], target_pos[:, 2]] == 0\n",
        "    target_non_zero_mask = target_map_data[target_pos[:, 0], target_pos[:, 1], target_pos[:, 2]] > 0\n",
        "    search_non_zero_mask = search_map_data[search_pos[:, 0], search_pos[:, 1], search_pos[:, 2]] > 0\n",
        "    search_non_zero_count = np.count_nonzero(np.multiply(target_zero_mask, search_non_zero_mask))\n",
        "\n",
        "    trimmed_target_vec = target_map_vec[target_pos[:, 0], target_pos[:, 1], target_pos[:, 2]]\n",
        "    trimmed_search_vec = search_map_vec[search_pos[:, 0], search_pos[:, 1], search_pos[:, 2]]\n",
        "\n",
        "    total += search_non_zero_count\n",
        "\n",
        "    sco_arr = np.zeros_like(search_map_data)\n",
        "    sco = np.einsum(\"ij,ij->i\", trimmed_target_vec, trimmed_search_vec)\n",
        "    sco_arr[search_pos[:, 0], search_pos[:, 1], search_pos[:, 2]] = sco\n",
        "    sco_sum = np.sum(sco_arr)\n",
        "    Nm = np.count_nonzero(np.multiply(target_non_zero_mask, search_non_zero_mask))\n",
        "\n",
        "    print(\n",
        "        \"Overlap= \"\n",
        "        + str(float(Nm) / float(total))\n",
        "        + \" \"\n",
        "        + str(Nm)\n",
        "        + \"/\"\n",
        "        + str(total)\n",
        "        + \" CC= \"\n",
        "        + str(cc / (std1 * std2))\n",
        "        + \" PCC= \"\n",
        "        + str(pcc / (pstd1 * pstd2))\n",
        "    )\n",
        "    print(\"Score=\", sco_sum)\n",
        "    return sco_arr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkZhl3mgjt2x"
      },
      "source": [
        "def fft_search_score_trans(target_X, target_Y, target_Z, search_vec, a, b, c, fft_object, ifft_object):\n",
        "    x2 = copy.deepcopy(search_vec[..., 0])\n",
        "    y2 = copy.deepcopy(search_vec[..., 1])\n",
        "    z2 = copy.deepcopy(search_vec[..., 2])\n",
        "\n",
        "    X2 = np.zeros_like(target_X)\n",
        "    np.copyto(a, x2)\n",
        "    np.copyto(X2, fft_object(a))\n",
        "    dot_X = target_X * X2\n",
        "    np.copyto(b, dot_X)\n",
        "    dot_x = np.zeros_like(x2)\n",
        "    np.copyto(dot_x, ifft_object(b))\n",
        "\n",
        "    Y2 = np.zeros_like(target_Y)\n",
        "    np.copyto(a, y2)\n",
        "    np.copyto(Y2, fft_object(a))\n",
        "    dot_Y = target_Y * Y2\n",
        "    np.copyto(b, dot_Y)\n",
        "    dot_y = np.zeros_like(y2)\n",
        "    np.copyto(dot_y, ifft_object(b))\n",
        "\n",
        "    Z2 = np.zeros_like(target_Z)\n",
        "    np.copyto(a, z2)\n",
        "    np.copyto(Z2, fft_object(a))\n",
        "    dot_Z = target_Z * Z2\n",
        "    np.copyto(b, dot_Z)\n",
        "    dot_z = np.zeros_like(z2)\n",
        "    np.copyto(dot_z, ifft_object(b))\n",
        "\n",
        "    return find_best_trans_list([dot_x, dot_y, dot_z])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSwjKq1PjxyR"
      },
      "source": [
        "def fft_search_best_dot(target_list, query_list, a, b, c, fft_object, ifft_object):\n",
        "    dot_product_list = []\n",
        "    for target_complex, query_real in zip(target_list, query_list):\n",
        "        \n",
        "        query_complex = np.zeros_like(target_complex)\n",
        "        np.copyto(a, query_real)\n",
        "        np.copyto(query_complex, fft_object(a))\n",
        "        dot_complex = target_complex * query_complex\n",
        "        np.copyto(b, dot_complex)\n",
        "        dot_real = np.zeros_like(query_real)\n",
        "        np.copyto(dot_real, ifft_object(b))\n",
        "        \n",
        "        dot_product_list.append(dot_real)\n",
        "        \n",
        "    return dot_product_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJJ6T8Rkj6pS"
      },
      "source": [
        "def fft_search_score_trans_1d(target_X, search_data, a, b, fft_object, ifft_object, mode, ave=None):\n",
        "\n",
        "    x2 = copy.deepcopy(search_data)\n",
        "\n",
        "    if mode == \"Overlap\":\n",
        "        x2 = np.where(x2 > 0, 1.0, 0.0)\n",
        "    elif mode == \"CC\":\n",
        "        x2 = np.where(x2 > 0, x2, 0.0)\n",
        "    elif mode == \"PCC\":\n",
        "        x2 = np.where(x2 > 0, x2 - ave, 0.0)\n",
        "    elif mode == \"Laplacian\":\n",
        "        weights = np.array(\n",
        "            [\n",
        "                [[0.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 0.0]],\n",
        "                [[0.0, 1.0, 0.0], [1.0, -6.0, 1.0], [0.0, 1.0, 0.0]],\n",
        "                [[0.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 0.0]],\n",
        "            ]\n",
        "        )\n",
        "        x2 = convolve(search_data, weights, mode=\"constant\")\n",
        "        #x2 = correlate(x2, weights, mode=\"constant\")\n",
        "\n",
        "    X2 = np.zeros_like(target_X)\n",
        "    np.copyto(a, x2)\n",
        "    np.copyto(X2, fft_object(a))\n",
        "    dot_X = target_X * X2\n",
        "    np.copyto(b, dot_X)\n",
        "    dot_x = np.zeros_like(x2)\n",
        "    np.copyto(dot_x, ifft_object(b))\n",
        "\n",
        "    return find_best_trans_list([dot_x])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYLVKEw8j7nT"
      },
      "source": [
        "def search_map_fft(mrc_target, mrc_search, TopN=10, ang=30, mode=\"VecProduct\", is_eval_mode=False, save_path=\".\"):\n",
        "\n",
        "    time_start = time.time()\n",
        "\n",
        "    if is_eval_mode:\n",
        "        print(\"#For Evaluation Mode\")\n",
        "        print(\"#Please use the same coordinate system and map size for map1 and map2.\")\n",
        "        print(\"#Example:\")\n",
        "        print(\"#In Chimera command line: open map1 and map2 as #0 and #1, then type\")\n",
        "        print(\"#> open map1.mrc\")\n",
        "        print(\"#> open map2.mrc\")\n",
        "        print(\"#> vop #1 resample onGrid #0\")\n",
        "        print(\"#> volume #2 save new.mrc\")\n",
        "        print(\"#Chimera will generate the resampled map2.mrc as new.mrc\")\n",
        "        return\n",
        "\n",
        "    #     x1 = copy.deepcopy(mrc_target.vec[:, :, :, 0])\n",
        "    #     y1 = copy.deepcopy(mrc_target.vec[:, :, :, 1])\n",
        "    #     z1 = copy.deepcopy(mrc_target.vec[:, :, :, 2])\n",
        "\n",
        "    # init the target map vectors\n",
        "    x1 = copy.deepcopy(mrc_target.vec[:, :, :, 0])\n",
        "\n",
        "    if mode == \"VecProduct\":\n",
        "        y1 = copy.deepcopy(mrc_target.vec[:, :, :, 1])\n",
        "        z1 = copy.deepcopy(mrc_target.vec[:, :, :, 2])\n",
        "\n",
        "    # Postprocessing for other modes\n",
        "    if mode == \"Overlap\":\n",
        "        x1 = np.where(mrc_target.data > 0, 1.0, 0.0)\n",
        "    elif mode == \"CC\":\n",
        "        x1 = np.where(mrc_target.data > 0, mrc_target.data, 0.0)\n",
        "    elif mode == \"PCC\":\n",
        "        x1 = np.where(mrc_target.data > 0, mrc_target.data - mrc_target.ave, 0.0)\n",
        "    elif mode == \"Laplacian\":\n",
        "        weights = np.array(\n",
        "            [\n",
        "                [[0.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 0.0]],\n",
        "                [[0.0, 1.0, 0.0], [1.0, -6.0, 1.0], [0.0, 1.0, 0.0]],\n",
        "                [[0.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 0.0]],\n",
        "            ]\n",
        "        )\n",
        "        x1 = convolve(mrc_target.data, weights, mode=\"constant\")\n",
        "        #x1 = correlate(mrc_target.data, weights, mode=\"constant\")\n",
        "\n",
        "    d3 = mrc_target.xdim ** 3\n",
        "\n",
        "    rd3 = 1.0 / d3\n",
        "\n",
        "    X1 = np.fft.rfftn(x1)\n",
        "    X1 = np.conj(X1)\n",
        "\n",
        "    if mode == \"VecProduct\":\n",
        "        Y1 = np.fft.rfftn(y1)\n",
        "        Y1 = np.conj(Y1)\n",
        "        Z1 = np.fft.rfftn(z1)\n",
        "        Z1 = np.conj(Z1)\n",
        "\n",
        "    x_angle = []\n",
        "    y_angle = []\n",
        "    z_angle = []\n",
        "\n",
        "    i = 0\n",
        "    while i < 360:\n",
        "        x_angle.append(i)\n",
        "        y_angle.append(i)\n",
        "        i += ang\n",
        "\n",
        "    i = 0\n",
        "    while i <= 180:\n",
        "        z_angle.append(i)\n",
        "        i += ang\n",
        "\n",
        "    angle_comb = np.array(np.meshgrid(x_angle, y_angle, z_angle)).T.reshape(-1, 3)\n",
        "    \n",
        "#     rot_vec_dict, rot_data_dict = rot_init_cuda(mrc_search.data, mrc_search.vec, angle_comb)\n",
        "\n",
        "    rot_vec_dict = {}\n",
        "    rot_data_dict = {}\n",
        "\n",
        "    with concurrent.futures.ThreadPoolExecutor(max_workers=os.cpu_count() + 4) as executor:\n",
        "        trans_vec = {executor.submit(rot_mrc, mrc_search.data, mrc_search.vec, angle,): angle for angle in angle_comb}\n",
        "        for future in concurrent.futures.as_completed(trans_vec):\n",
        "            angle = trans_vec[future]\n",
        "            rot_vec_dict[tuple(angle)] = future.result()[0]\n",
        "            rot_data_dict[tuple(angle)] = future.result()[1]\n",
        "\n",
        "    time_rot = time.time()\n",
        "\n",
        "    print(\"Rotation time: \" + str(time_rot-time_start))\n",
        "\n",
        "    # fftw plans\n",
        "    a = pyfftw.empty_aligned((x1.shape), dtype=\"float32\")\n",
        "    b = pyfftw.empty_aligned((a.shape[0], a.shape[1], a.shape[2] // 2 + 1), dtype=\"complex64\")\n",
        "    c = pyfftw.empty_aligned((x1.shape), dtype=\"float32\")\n",
        "\n",
        "    fft_object = pyfftw.FFTW(a, b, axes=(0, 1, 2))\n",
        "    ifft_object = pyfftw.FFTW(b, c, direction=\"FFTW_BACKWARD\", axes=(0, 1, 2), normalise_idft=False)\n",
        "\n",
        "    angle_score = []\n",
        "\n",
        "    for angle in tqdm(angle_comb, desc=\"FFT Process\"):\n",
        "        rot_mrc_vec = rot_vec_dict[tuple(angle)]\n",
        "        rot_mrc_data = rot_data_dict[tuple(angle)]\n",
        "\n",
        "        if mode == \"VecProduct\":\n",
        "            \n",
        "            x2 = copy.deepcopy(rot_mrc_vec[..., 0])\n",
        "            y2 = copy.deepcopy(rot_mrc_vec[..., 1])\n",
        "            z2 = copy.deepcopy(rot_mrc_vec[..., 2])\n",
        "                    \n",
        "            target_list = [X1, Y1, Z1]\n",
        "            query_list = [x2, y2, z2]\n",
        "            \n",
        "            fft_result_list = fft_search_best_dot(target_list, query_list, a, b, c, fft_object, ifft_object)\n",
        "                    \n",
        "            best, trans = find_best_trans_list(fft_result_list)\n",
        "            \n",
        "        else:\n",
        "            best, trans = fft_search_score_trans_1d(\n",
        "                X1, rot_mrc_data, a, b, fft_object, ifft_object, mode, mrc_target.ave\n",
        "            )\n",
        "            if mode == \"CC\":\n",
        "                rstd2 = 1.0 / mrc_target.std ** 2\n",
        "                best = best * rstd2\n",
        "            if mode == \"PCC\":\n",
        "                rstd3 = 1.0 / mrc_target.std_norm_ave ** 2\n",
        "                best = best * rstd3\n",
        "\n",
        "        angle_score.append([tuple(angle), best * rd3, trans])\n",
        "\n",
        "    # calculate the ave and std\n",
        "    score_arr = np.array([row[1] for row in angle_score])\n",
        "    ave = np.mean(score_arr)\n",
        "    std = np.std(score_arr)\n",
        "    print(\"Std= \" + str(std) + \" Ave= \" + str(ave))\n",
        "\n",
        "    # sort the list and get topN\n",
        "    sorted_topN = sorted(angle_score, key=lambda x: x[1], reverse=True)[:TopN]\n",
        "\n",
        "    for x in sorted_topN:\n",
        "        print(x)\n",
        "\n",
        "    time_fft = time.time()\n",
        "\n",
        "    print(\"FFT time: \" + str(time_fft-time_rot))\n",
        "\n",
        "    refined_score = []  \n",
        "    if ang > 5.0:\n",
        "        \n",
        "        # setup all the angles for refinement\n",
        "        # initialize the refinement list by Â±5 degrees\n",
        "        refine_ang_list = []\n",
        "        for t_mrc in sorted_topN: \n",
        "            curr_ang_arr = np.array(\n",
        "                np.meshgrid(\n",
        "                    [t_mrc[0][0] - 5, t_mrc[0][0], t_mrc[0][0] + 5],\n",
        "                    [t_mrc[0][1] - 5, t_mrc[0][1], t_mrc[0][1] + 5],\n",
        "                    [t_mrc[0][2] - 5, t_mrc[0][2], t_mrc[0][2] + 5],\n",
        "                )\n",
        "            ).T.reshape(-1, 3)\n",
        "            refine_ang_list.append(curr_ang_arr)\n",
        "        \n",
        "        refine_ang_arr = np.concatenate(refine_ang_list, axis=0)\n",
        "        print(refine_ang_arr.shape)\n",
        "        \n",
        "        # rotate the mrc vector and data according to the list (multi-threaded)\n",
        "        with concurrent.futures.ThreadPoolExecutor(max_workers=os.cpu_count() + 4) as executor:\n",
        "            trans_vec = {executor.submit(rot_mrc, mrc_search.data, mrc_search.vec, angle,): angle for angle in refine_ang_arr}\n",
        "            for future in concurrent.futures.as_completed(trans_vec):\n",
        "                angle = trans_vec[future]\n",
        "                rot_vec_dict[tuple(angle)] = future.result()[0]\n",
        "                rot_data_dict[tuple(angle)] = future.result()[1]\n",
        "                \n",
        "        for angle in tqdm(refine_ang_arr, desc=\"Refine FFT Process\"):\n",
        "            \n",
        "            rot_mrc_vec = rot_vec_dict[tuple(angle)]\n",
        "            rot_mrc_data = rot_data_dict[tuple(angle)]\n",
        "            \n",
        "            if mode == \"VecProduct\":\n",
        "                x2 = copy.deepcopy(rot_mrc_vec[..., 0])\n",
        "                y2 = copy.deepcopy(rot_mrc_vec[..., 1])\n",
        "                z2 = copy.deepcopy(rot_mrc_vec[..., 2])\n",
        "                    \n",
        "                target_list = [X1, Y1, Z1]\n",
        "                query_list = [x2, y2, z2]\n",
        "            \n",
        "                fft_result_list = fft_search_best_dot(target_list, query_list, a, b, c, fft_object, ifft_object)\n",
        "                best, trans = find_best_trans_list(fft_result_list)\n",
        "            \n",
        "            else:\n",
        "                best, trans = fft_search_score_trans_1d(\n",
        "                    X1, rot_mrc_data, a, b, fft_object, ifft_object, mode, mrc_target.ave\n",
        "                )\n",
        "                if mode == \"CC\":\n",
        "                    rstd2 = 1.0 / mrc_target.std ** 2\n",
        "                    best = best * rstd2\n",
        "                if mode == \"PCC\":\n",
        "                    rstd3 = 1.0 / mrc_target.std_norm_ave ** 2\n",
        "                    best = best * rstd3\n",
        "        \n",
        "            refined_score.append([tuple(angle), best * rd3, trans, rot_mrc_vec, rot_mrc_data])\n",
        "            \n",
        "        refined_list = sorted(refined_score, key=lambda x: x[1], reverse=True)[:TopN]\n",
        "    \n",
        "    else:\n",
        "        refined_list = sorted_topN\n",
        "\n",
        "    time_refine = time.time()\n",
        "\n",
        "    print(\"Refinement time: \" + str(time_refine-time_fft))\n",
        "    \n",
        "    # Save the results to file\n",
        "    for i, t_mrc in enumerate(refined_list):\n",
        "        \n",
        "        # calculate the scores\n",
        "        print(\"R=\" + str(t_mrc[0]) + \" T=\" + str(t_mrc[2]))\n",
        "        sco = get_score(\n",
        "            mrc_target.data,\n",
        "            t_mrc[4],\n",
        "            mrc_target.vec,\n",
        "            t_mrc[3],\n",
        "            t_mrc[2],\n",
        "            mrc_target.ave,\n",
        "            mrc_search.ave,\n",
        "            mrc_target.std,\n",
        "            mrc_search.std,\n",
        "            mrc_target.std_norm_ave,\n",
        "            mrc_search.std_norm_ave,\n",
        "        )\n",
        "        \n",
        "        # Write result to PDB files\n",
        "        #show_vec(mrc_target.orig, t_mrc[3], t_mrc[4], sco, mrc_search.xwidth, t_mrc[2], \"model_top_\" + str(i + 1) + \".pdb\", save_path)\n",
        "\n",
        "        # Write result to MRC files\n",
        "        save_match_mrc(save_path=save_path, file_name=\"model_top_\" + str(i + 1) + \".mrc\", orig_file_path = mrc_query_path, rot_ang=t_mrc[0], trans_arr=t_mrc[2], sampled_shape=t_mrc[4].shape[0])\n",
        "\n",
        "    time_writefile = time.time()\n",
        "\n",
        "    print(\"File Write time: \" + str(time_writefile-time_refine))\n",
        "\n",
        "    return refined_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmK8Bf_I2wHt"
      },
      "source": [
        "import itertools\n",
        "def rotation3d(image, theta_x, theta_y, theta_z, output_spacing = None, background_value=0.0):\n",
        "    \"\"\"\n",
        "    This function rotates an image across each of the x, y, z axes by theta_x, theta_y, and theta_z degrees\n",
        "    respectively (euler ZXY orientation) and resamples it to be isotropic.\n",
        "    :param image: An sitk 3D image\n",
        "    :param theta_x: The amount of degrees the user wants the image rotated around the x axis\n",
        "    :param theta_y: The amount of degrees the user wants the image rotated around the y axis\n",
        "    :param theta_z: The amount of degrees the user wants the image rotated around the z axis\n",
        "    :param output_spacing: Scalar denoting the isotropic output image spacing. If None, then use the smallest\n",
        "                           spacing from original image.\n",
        "    :return: The rotated image\n",
        "    \"\"\"\n",
        "    r = R.from_euler('ZYX', [theta_x, theta_y, theta_z], degrees=True)\n",
        "    euler = r.as_euler('ZYX')\n",
        "\n",
        "    euler_transform = sitk.Euler3DTransform (image.TransformContinuousIndexToPhysicalPoint([(sz-1)/2.0 for sz in image.GetSize()]), \n",
        "                                             euler[0], \n",
        "                                             euler[1], \n",
        "                                             euler[2])\n",
        "\n",
        "    # compute the resampling grid for the transformed image\n",
        "    max_indexes = [sz-1 for sz in image.GetSize()]\n",
        "    extreme_indexes = list(itertools.product(*(list(zip([0]*image.GetDimension(),max_indexes)))))\n",
        "    extreme_points_transformed = [euler_transform.TransformPoint(image.TransformContinuousIndexToPhysicalPoint(p)) for p in extreme_indexes]\n",
        "    \n",
        "    output_min_coordinates = np.min(extreme_points_transformed, axis=0)\n",
        "    output_max_coordinates = np.max(extreme_points_transformed, axis=0)\n",
        "    \n",
        "    # isotropic ouput spacing\n",
        "    if output_spacing is None:\n",
        "      output_spacing = min(image.GetSpacing())\n",
        "    output_spacing = [output_spacing]*image.GetDimension()  \n",
        "                    \n",
        "    output_origin = output_min_coordinates\n",
        "    output_size = [int(((omx-omn)/ospc)+0.5)  for ospc, omn, omx in zip(output_spacing, output_min_coordinates, output_max_coordinates)]\n",
        "    \n",
        "    output_direction = [1,0,0,0,1,0,0,0,1]\n",
        "    output_pixeltype = image.GetPixelIDValue()\n",
        "\n",
        "    return sitk.Resample(image, \n",
        "                         output_size, \n",
        "                         euler_transform.GetInverse(), \n",
        "                         sitk.sitkNearestNeighbor, \n",
        "                         output_origin,\n",
        "                         output_spacing,\n",
        "                         output_direction,\n",
        "                         background_value,\n",
        "                         output_pixeltype) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_o-0Bzgs3s5r"
      },
      "source": [
        "def save_match_mrc(save_path, file_name, orig_file_path, rot_ang, trans_arr, sampled_shape):\n",
        "\n",
        "  trans_arr = np.array(trans_arr)\n",
        "\n",
        "  if 2 * trans_arr[0] > sampled_shape:\n",
        "    trans_arr[0] -= sampled_shape\n",
        "  if 2 * trans_arr[1] > sampled_shape:\n",
        "    trans_arr[1] -= sampled_shape\n",
        "  if 2 * trans_arr[2] > sampled_shape:\n",
        "    trans_arr[2] -= sampled_shape\n",
        "\n",
        "\n",
        "  complete_name = os.path.join(save_path, file_name)\n",
        "\n",
        "  query_mrc = mrcfile.open(orig_file_path, mode='r')\n",
        "\n",
        "  euler3d = sitk.Euler3DTransform()\n",
        "  img = sitk.GetImageFromArray(query_mrc.data)\n",
        "  # set the center for rotation\n",
        "  euler3d.SetCenter(img.TransformContinuousIndexToPhysicalPoint(np.array(img.GetSize())/2.0))\n",
        "  resampled_img = rotation3d(img, rot_ang[0], rot_ang[1], rot_ang[2])\n",
        "  data_arr = sitk.GetArrayFromImage(resampled_img)\n",
        "  \n",
        "  with mrcfile.new(complete_name, overwrite=True) as mrc:\n",
        "    mrc.set_data(data_arr)\n",
        "\n",
        "    # mrc.header.origin['x'] = np.array([-trans_arr[0] * query_mrc.data.shape[0] * 1.0 / sampled_shape])\n",
        "    # mrc.header.origin['y'] = np.array([-trans_arr[1] * query_mrc.data.shape[1] * 1.0 / sampled_shape])\n",
        "    # mrc.header.origin['z'] = np.array([-trans_arr[2] * query_mrc.data.shape[2] * 1.0 / sampled_shape])\n",
        "\n",
        "    # print(trans_arr[0], sampled_shape, query_mrc.voxel_size['x'].item(), query_mrc.data.shape[0], mrc.header.origin['x'])\n",
        "    # print(trans_arr[1], sampled_shape, query_mrc.voxel_size['y'].item(), query_mrc.data.shape[1], mrc.header.origin['y'])\n",
        "    # print(trans_arr[2], sampled_shape, query_mrc.voxel_size['z'].item(), query_mrc.data.shape[2], mrc.header.origin['z'])\n",
        "\n",
        "    mrc.close()\n",
        "\n",
        "  query_mrc.close()\n",
        "  return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e33xft6ekCAB"
      },
      "source": [
        "def show_vec(origin, sampled_mrc_vec, sampled_mrc_data, sampled_mrc_score, sample_width, trans, file_name, save_path):\n",
        "\n",
        "    complete_name = os.path.join(save_path, file_name)\n",
        "\n",
        "    dim = sampled_mrc_data.shape[0]\n",
        "\n",
        "    trans = np.array(trans)\n",
        "\n",
        "    if 2 * trans[0] > dim:\n",
        "        trans[0] -= dim\n",
        "    if 2 * trans[1] > dim:\n",
        "        trans[1] -= dim\n",
        "    if 2 * trans[2] > dim:\n",
        "        trans[2] -= dim\n",
        "\n",
        "    add = origin - trans * sample_widh\n",
        "\n",
        "    natm = 1\n",
        "    nres = 1\n",
        "\n",
        "    with open(complete_name, \"w\") as pdb_file:\n",
        "      for x in range(dim):\n",
        "          for y in range(dim):\n",
        "              for z in range(dim):\n",
        "\n",
        "                  if sampled_mrc_data[x][y][z] != 0.0:\n",
        "                      tmp = np.array([x, y, z])\n",
        "                      tmp = tmp * sample_width + add\n",
        "                      atom_header = \"ATOM{:>7d}  CA  ALA{:>6d}    \".format(natm, nres)\n",
        "                      atom_content = \"{:8.3f}{:8.3f}{:8.3f}{:6.2f}{:6.2f}\".format(\n",
        "                          tmp[0], tmp[1], tmp[2], 1.0, sampled_mrc_score[x][y][z]\n",
        "                      )\n",
        "                      pdb_file.write(atom_header + atom_content + \"\\n\")\n",
        "                      natm += 1\n",
        "\n",
        "                      tmp = np.array([x, y, z])\n",
        "                      tmp = (tmp + sampled_mrc_vec[x][y][z]) * sample_width + add\n",
        "                      atom_header = \"ATOM{:>7d}  CB  ALA{:>6d}    \".format(natm, nres)\n",
        "                      atom_content = \"{:8.3f}{:8.3f}{:8.3f}{:6.2f}{:6.2f}\".format(\n",
        "                          tmp[0], tmp[1], tmp[2], 1.0, sampled_mrc_score[x][y][z]\n",
        "                      )\n",
        "                      pdb_file.write(atom_header + atom_content + \"\\n\")\n",
        "                      natm += 1\n",
        "                      nres += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHLrYJtbvv_8"
      },
      "source": [
        "## Change the parameters below before running the cell:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TzfTWcnuxUe"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAFSMkGzpvqJ"
      },
      "source": [
        "#@title Tweak Parameters { run: \"auto\" }\n",
        "#@markdown ---\n",
        "#@markdown **vox_size**: Sampling voxel spacing, default=7.0 <br />\n",
        "#@markdown **sample_ang**: Sampling angle spacing, default=30.0 <br />\n",
        "#@markdown **dens_thres_target**: Filtering threshold of target density map, default=0.0 <br />\n",
        "#@markdown **dens_thres_query**: Filtering threshold of query density map, default=0.0 <br />\n",
        "#@markdown **gaussian_bandwith**: Bandwidth of the Gaussian filter, default=16.0 <br />\n",
        "#@markdown **topN**: Number of top models to save, default=10, set to 0 to disable <br />\n",
        "#@markdown **match_mode**: Mode for VESPER, possible values: \"VecProduct\", \"Overlap\", \"CC\", \"PCC\", \"Laplacian\", default=\"VecProduct\" <br />\n",
        "#@markdown **mrc_target_path**: Path for target map <br />\n",
        "#@markdown **mrc_query_path**: Path for query map <br />\n",
        "#@markdown **output_path**: Path for output mrc files, note that if using current directory, all data are gone once disconnect from instance <br />\n",
        "\n",
        "#@markdown ---\n",
        "vox_size = 7.0 #@param {type:\"number\"}\n",
        "sample_ang = 30.0 #@param {type:\"number\"}   \n",
        "dens_thres_target = 0.01 #@param {type:\"number\"}\n",
        "dens_thres_query = 0.01 #@param {type:\"number\"}\n",
        "gaussian_bandwith = 16.0 #@param {type:\"number\"}                                          \n",
        "topN = 10 #@param {type:\"slider\", min:0, max:100, step:1}\n",
        "match_mode = \"VecProduct\" #@param [\"VecProduct\", \"Overlap\", \"CC\", \"PCC\", \"Laplacian\"]\n",
        "\n",
        "# mrc_target_path = \"/content/drive/MyDrive/Data/emd_8097.mrc\" #@param {type:\"string\"}\n",
        "# mrc_query_path = \"/content/drive/MyDrive/Data/ChainA_simulated_resample.mrc\" #@param {type:\"string\"}\n",
        "\n",
        "mrc_target_path = \"/content/drive/MyDrive/Data/emd_8097.mrc\" #@param {type:\"string\"}\n",
        "mrc_query_path = \"/content/drive/MyDrive/Data/ChainA_simulated_resample.mrc\" #@param {type:\"string\"}\n",
        "output_path = \".\" #@param {type:\"string\"}\n",
        "#@markdown ---"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ir8rZeuKugH9"
      },
      "source": [
        "target_mrc_obj = mrc_obj(mrc_target_path)\n",
        "query_mrc_obj = mrc_obj(mrc_query_path)\n",
        "\n",
        "target_mrc_obj, mrc_N1 = mrc_set_vox_size(target_mrc_obj, th=dens_thres_target, voxel_size=vox_size)\n",
        "query_mrc_obj, mrc_N2 = mrc_set_vox_size(query_mrc_obj, th=dens_thres_query, voxel_size=vox_size)\n",
        "\n",
        "if mrc_N1.xdim > mrc_N2.xdim:\n",
        "    dim = mrc_N2.xdim = mrc_N2.ydim = mrc_N2.zdim = mrc_N1.xdim\n",
        "    mrc_N2.orig = mrc_N2.cent - 0.5 * vox_size * mrc_N2.xdim\n",
        "else:\n",
        "    dim = mrc_N1.xdim = mrc_N1.ydim = mrc_N1.zdim = mrc_N2.xdim\n",
        "    mrc_N1.orig = mrc_N1.cent - 0.5 * vox_size * mrc_N1.xdim\n",
        "\n",
        "mrc_N1.dens = np.zeros((dim ** 3, 1))\n",
        "mrc_N1.vec = np.zeros((dim, dim, dim, 3), dtype=\"float32\")\n",
        "mrc_N1.data = np.zeros((dim, dim, dim))\n",
        "mrc_N2.dens = np.zeros((dim ** 3, 1))\n",
        "mrc_N2.vec = np.zeros((dim, dim, dim, 3), dtype=\"float32\")\n",
        "mrc_N2.data = np.zeros((dim, dim, dim))\n",
        "\n",
        "mrc_N1 = fastVEC(target_mrc_obj, mrc_N1, dreso=gaussian_bandwith)\n",
        "mrc_N2 = fastVEC(query_mrc_obj, mrc_N2, dreso=gaussian_bandwith)\n",
        "\n",
        "score_list = search_map_fft(mrc_N1, mrc_N2, TopN=topN, ang=sample_ang, mode=match_mode, save_path=output_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wN9eCkld0FOl"
      },
      "source": [
        "## Result Visualization (Optional):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bH--zlQN0LHx"
      },
      "source": [
        "!pip install biopython nglview ipywidgets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-7ecdHS0Vz5"
      },
      "source": [
        "import nglview as nv\n",
        "import ipywidgets\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pmc3T9_b6-7K"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}